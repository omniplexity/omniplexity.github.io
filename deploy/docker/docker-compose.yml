# OmniAI Docker Compose - Production Deployment
# Runs FastAPI backend + ngrok tunnel sidecar
#
# Usage:
#   1. cp .env.example .env && edit .env (add NGROK_AUTHTOKEN)
#   2. docker compose up -d

services:
  backend:
    build:
      context: ../..
      dockerfile: deploy/docker/Dockerfile.backend
    container_name: omniai-backend
    init: true
    env_file:
      - .env
    environment:
      # Database path inside container (volume-mounted)
      - DATABASE_URL=sqlite:////app/data/omniplexity.db
    volumes:
      # Persist SQLite database
      - ../../data:/app/data
    # Linux compatibility: enables host.docker.internal for LLM providers on host
    extra_hosts:
      - "host.docker.internal:host-gateway"
    networks:
      - internal
    restart: unless-stopped
    read_only: true
    tmpfs:
      - /tmp
    security_opt:
      - no-new-privileges:true
    cap_drop:
      - ALL
    stop_grace_period: 30s
    # NO ports published to host - access only via ngrok tunnel
    healthcheck:
      test: ["CMD", "python", "-c", "import urllib.request as r; r.urlopen('http://127.0.0.1:8787/health', timeout=3)"]
      interval: 30s
      timeout: 5s
      retries: 3
      start_period: 10s

  ngrok:
    image: ngrok/ngrok:latest
    container_name: omniai-ngrok
    init: true
    command:
      - "http"
      - "http://backend:8787"
      - "--request-header-add=X-Origin-Secret:${ORIGIN_LOCK_SECRET}"
    environment:
      - NGROK_AUTHTOKEN=${NGROK_AUTHTOKEN}
      - NGROK_LOG=stdout
      - NGROK_LOG_FORMAT=json
    depends_on:
      backend:
        condition: service_healthy
    networks:
      - internal
    restart: unless-stopped
    security_opt:
      - no-new-privileges:true
    cap_drop:
      - ALL
    stop_grace_period: 15s
    # Expose ngrok web interface for URL inspection (optional, localhost only)
    ports:
      - "127.0.0.1:4040:4040"

networks:
  internal:
    driver: bridge
